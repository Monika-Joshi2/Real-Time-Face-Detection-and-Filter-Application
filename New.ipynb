{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21ef3b20-6d1d-4284-9e50-4a18c3f98753",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sharpen_image(image):\n",
    "        # Define a sharpening kernel\n",
    "    kernel = np.array([[0, -1, 0],\n",
    "                        [-1, 5, -1],\n",
    "                        [0, -1, 0]])\n",
    "        \n",
    "        # Apply the kernel using filter2D\n",
    "    sharpened = cv2.filter2D(image, -1, kernel)\n",
    "        \n",
    "    return sharpened\n",
    "    \n",
    "def sketch(image):\n",
    "        # Load the image in grayscale \n",
    "        # Step 1: Invert the grayscale image (negative of the image)\n",
    "    inverted_image = cv2.bitwise_not(image)\n",
    "        \n",
    "        # Step 2: Apply a Gaussian blur to the inverted image\n",
    "    blurred_image = cv2.GaussianBlur(inverted_image, (21, 21), 0)\n",
    "        \n",
    "        # Step 3: Invert the blurred image\n",
    "    inverted_blurred = cv2.bitwise_not(blurred_image)\n",
    "        \n",
    "        # Step 4: Create the sketch effect by dividing the original image by the inverted blurred image\n",
    "    sketch = cv2.divide(image, inverted_blurred, scale=256.0)\n",
    "        \n",
    "    sketch=sharpen_image(sketch)\n",
    "        # Step 5: Reduce exposure in the final sketch\n",
    "    exposure_factor = 0.5  # Adjust this factor (between 0 and 1) to reduce exposure\n",
    "    sketch = np.clip(sketch * exposure_factor, 0, 255).astype(np.uint8)\n",
    "    sketch=cv2.cvtColor(sketch, cv2.COLOR_BGR2GRAY)\n",
    "    return sketch\n",
    "    \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8db7a83b-0e51-442d-8c0a-5aec3622e560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fil1(face, frame):\n",
    "    x, y, w, h=face\n",
    "    x1=x+int(2*(w/6))\n",
    "    y1=y+int(2*(h/6)+10)\n",
    "    w1=int(w/3)\n",
    "    h1=int(h/3)\n",
    "    \n",
    "                    #frame=cv2.rectangle(frame, (x,y), (x+w, y+h), (255, 0, 0), 3)\n",
    "    k=cv2.imread(r\"C:\\Users\\joshi\\Documents\\EDGE AI\\Face_Detection\\Images\\pig.png\", cv2.IMREAD_UNCHANGED)\n",
    "    k1=cv2.resize(k, (w1,h1))  \n",
    "    \n",
    "    bgr=k1[:, :, :3]  #BGR channels\n",
    "    alpha=k1[:,:,3]/255.0 #Alpha channel normalized to 0-1\n",
    "                \n",
    "                        #Extracting the region of interest from the frame\n",
    "    roi=frame[y1:y1+h1, x1:x1+h1]\n",
    "                \n",
    "                        #Blend the png image and the roi using alpha channel\n",
    "                \n",
    "    for c in range(0,3):\n",
    "        roi[:, :,c]=roi[:,:,c]*(1-alpha)+bgr[:,:,c]*alpha\n",
    "                \n",
    "                        #Place the blended image back into the frame\n",
    "                        \n",
    "                        #p.append(x,y,w,h)\n",
    "                        \n",
    "    frame[y1:y1+h1, x1:x1+w1]=roi\n",
    "    return frame\n",
    "\n",
    "\n",
    "def filter(val, frame):\n",
    "    import cv2\n",
    "    import os\n",
    "    import numpy as np\n",
    "    face_cascade = cv2.CascadeClassifier(\"C:/Users/joshi/Documents/EDGE AI/Face_Detection/haarcascade_frontalface_default.xml\")\n",
    "    gray_image=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    detections=face_cascade.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=6)\n",
    "    for face in detections: \n",
    "        if (val==1):\n",
    "            frame=fil1(face, frame)\n",
    "\n",
    "    return frame\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0eecde7-012b-485d-8d19-66cff23162fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def portrait(frame):\n",
    "    import mediapipe as mp\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose()\n",
    "    mp_face_detection = mp.solutions.face_detection\n",
    "    face_detection = mp_face_detection.FaceDetection()\n",
    "    \n",
    "    # Function to expand landmark points (more in x-direction)\n",
    "    def expand_points_x_direction(points, width, height, x_offset=50, y_offset=10):\n",
    "        expanded_points = []\n",
    "        for (x, y) in points:\n",
    "            expanded_x_left = np.clip(x - x_offset + 30, 0, width)\n",
    "            expanded_x_right = np.clip(x + x_offset - 30, 0, width)\n",
    "            expanded_y_up = np.clip(y - y_offset - 100, 0, height)\n",
    "            expanded_y_down = np.clip(y + y_offset, 0, height)\n",
    "            \n",
    "            expanded_points.append((expanded_x_left, expanded_y_up))\n",
    "            expanded_points.append((expanded_x_right, expanded_y_down))\n",
    "        \n",
    "        return expanded_points\n",
    "    \n",
    "    \n",
    "        # Convert the frame to RGB for MediaPipe processing\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "        # Detect human pose\n",
    "    pose_result = pose.process(rgb_frame)\n",
    "        \n",
    "        # Detect face in the frame\n",
    "    face_result = face_detection.process(rgb_frame)\n",
    "    \n",
    "        # Create a mask for the human body\n",
    "    mask = np.zeros_like(frame, dtype=np.uint8)\n",
    "    \n",
    "    height, width, _ = frame.shape\n",
    "    \n",
    "        # If body landmarks are detected\n",
    "    if pose_result.pose_landmarks:\n",
    "            # Collect all body landmark points\n",
    "        body_points = []\n",
    "        for landmark in pose_result.pose_landmarks.landmark:\n",
    "            x = int(landmark.x * width)\n",
    "            y = int(landmark.y * height)\n",
    "            body_points.append((x, y))\n",
    "    \n",
    "            # Expand the points (more expansion in x-direction)\n",
    "        expanded_body_points = expand_points_x_direction(body_points, width, height, x_offset=50, y_offset=30)\n",
    "    \n",
    "            # Convert the points into a numpy array\n",
    "        body_points = np.array(expanded_body_points)\n",
    "    \n",
    "            # Draw the convex hull around the expanded body points\n",
    "        if len(body_points) > 0:\n",
    "            hull = cv2.convexHull(body_points)\n",
    "    \n",
    "                # Fill the convex hull on the mask\n",
    "            cv2.fillConvexPoly(mask, hull, (255, 255, 255))\n",
    "    \n",
    "        # If face landmarks are detected, exclude the face from being blurred\n",
    "    if face_result.detections:\n",
    "        for detection in face_result.detections:\n",
    "            bboxC = detection.location_data.relative_bounding_box\n",
    "            x_min = int(bboxC.xmin * width)\n",
    "            y_min = int(bboxC.ymin * height)\n",
    "            w = int(bboxC.width * width)\n",
    "            h = int(bboxC.height * height)\n",
    "    \n",
    "                # Draw a white rectangle (mask) over the face region\n",
    "            cv2.rectangle(mask, (x_min, y_min), (x_min + w, y_min + h), (255, 255, 255), -1)\n",
    "    \n",
    "        # Dilate the mask to ensure it covers all areas around the body\n",
    "    kernel = np.ones((15, 15), np.uint8)  # Dilation kernel size\n",
    "    dilated_mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "    \n",
    "        # Convert the mask to grayscale\n",
    "    gray_mask = cv2.cvtColor(dilated_mask, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        # Create a binary mask (human body and face as white, background as black)\n",
    "    _, binary_mask = cv2.threshold(gray_mask, 1, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "        # Invert the mask to blur only the background\n",
    "    inverted_mask = cv2.bitwise_not(binary_mask)\n",
    "    \n",
    "        # Blur the background\n",
    "    blurred_frame = cv2.GaussianBlur(frame, (21, 21), 30)\n",
    "    \n",
    "        # Combine the blurred background with the original body and face (excluding hair blur)\n",
    "    foreground = cv2.bitwise_and(frame, frame, mask=binary_mask)\n",
    "    background = cv2.bitwise_and(blurred_frame, blurred_frame, mask=inverted_mask)\n",
    "    \n",
    "        # Combine foreground and background\n",
    "    result_frame = cv2.add(foreground, background)\n",
    "    return result_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b065749-d5a1-44ea-b045-a25b0c3f033f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshi\\OneDrive\\Documents\\anaconda3\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Photo saved!\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import ttk\n",
    "import cv2\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "\n",
    "class PhotoEditorApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Photo Editor\")\n",
    "        self.root.geometry(\"800x600\")\n",
    "\n",
    "        self.video_source = 0\n",
    "        self.vid = cv2.VideoCapture(self.video_source)\n",
    "        \n",
    "        self.canvas = tk.Canvas(self.root, width=640, height=480)\n",
    "        self.canvas.pack()\n",
    "\n",
    "        self.filter_option = tk.StringVar(value=\"None\")\n",
    "        self.show_video = True  # Flag to toggle between video feed and uploaded image\n",
    "        self.uploaded_image = None  # Placeholder for the uploaded image\n",
    "\n",
    "        # Control buttons\n",
    "        self.create_controls()\n",
    "\n",
    "        self.update_frame()\n",
    "\n",
    "    def create_controls(self):\n",
    "        control_frame = tk.Frame(self.root)\n",
    "        control_frame.pack(side=tk.TOP, pady=10)\n",
    "\n",
    "        btn_capture = ttk.Button(control_frame, text=\"Capture Photo\", command=self.capture_photo)\n",
    "        btn_capture.grid(row=0, column=0, padx=10)\n",
    "\n",
    "        btn_upload = ttk.Button(control_frame, text=\"Upload Photo\", command=self.upload_photo)\n",
    "        btn_upload.grid(row=0, column=1, padx=10)\n",
    "\n",
    "        filter_label = ttk.Label(control_frame, text=\"Select Filter:\")\n",
    "        filter_label.grid(row=0, column=2, padx=10)\n",
    "\n",
    "        filter_menu = ttk.OptionMenu(control_frame, self.filter_option, \"None\", \"Sketch\", \"Piggy\", \"Portrait\")\n",
    "        filter_menu.grid(row=0, column=3, padx=10)\n",
    "\n",
    "        btn_magic_eraser = ttk.Button(control_frame, text=\"Magic Eraser\", command=self.magic_eraser_tool)\n",
    "        btn_magic_eraser.grid(row=0, column=4, padx=10)\n",
    "\n",
    "        btn_show_video = ttk.Button(control_frame, text=\"Show Video\", command=self.show_video_feed)\n",
    "        btn_show_video.grid(row=0, column=5, padx=10)\n",
    "\n",
    "    def update_frame(self):\n",
    "        global frame1\n",
    "        # If the flag is set to show video, capture and display the video feed\n",
    "        if self.show_video:\n",
    "            ret, frame = self.vid.read()\n",
    "            if ret:\n",
    "                frame = self.apply_filter(frame)\n",
    "                frame1=frame\n",
    "                self.photo = ImageTk.PhotoImage(image=Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)))\n",
    "                self.canvas.create_image(0, 0, image=self.photo, anchor=tk.NW)\n",
    "        else:\n",
    "            # If an image is uploaded, display the uploaded image\n",
    "            if self.uploaded_image is not None:\n",
    "                img = cv2.cvtColor(np.array(self.uploaded_image), cv2.COLOR_RGB2BGR)\n",
    "                img = self.apply_filter(img)\n",
    "                frame1=img\n",
    "                self.photo = ImageTk.PhotoImage(image=Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)))\n",
    "                self.canvas.create_image(0, 0, image=self.photo, anchor=tk.NW)\n",
    "\n",
    "        self.root.after(10, self.update_frame)\n",
    "\n",
    "    def apply_filter(self, frame):\n",
    "        filter_choice = self.filter_option.get()\n",
    "        if filter_choice == \"Sketch\":\n",
    "            return sketch(frame)\n",
    "        elif filter_choice == \"Piggy\":\n",
    "            return filter(1,frame)\n",
    "        elif filter_choice == \"Portrait\":\n",
    "            return portrait(frame)\n",
    "        return frame\n",
    "\n",
    " \n",
    "    def capture_photo(self):\n",
    "        if self.show_video:\n",
    "            ret = self.vid.read()\n",
    "            if ret:\n",
    "                cv2.imwrite(\"captured_image.jpg\", frame1)\n",
    "                print(\"Photo saved!\")\n",
    "\n",
    "        else:\n",
    "            cv2.imwrite(\"captured_image.jpg\", frame1)\n",
    "            print(\"Photo saved!\")\n",
    "\n",
    "    def upload_photo(self):\n",
    "        file_path = filedialog.askopenfilename(filetypes=[(\"Image Files\", \".jpg;.jpeg;*.png\")])\n",
    "        if file_path:\n",
    "            img = Image.open(file_path)\n",
    "            img = img.resize((640, 480))  # Resize to fit canvas size\n",
    "            self.uploaded_image = img\n",
    "            self.show_video = False  # Stop showing video when an image is uploaded\n",
    "\n",
    "    def magic_eraser_tool(self):\n",
    "        #yet to implement\n",
    "        print(\"NULL\")\n",
    "\n",
    "    def show_video_feed(self):\n",
    "        # Re-enable video feed and hide the uploaded image\n",
    "        self.show_video = True\n",
    "\n",
    "    def __del__(self):\n",
    "        if self.vid.isOpened():\n",
    "            self.vid.release()\n",
    "\n",
    "# Run the application\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = PhotoEditorApp(root)\n",
    "    root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
